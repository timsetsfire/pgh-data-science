{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%md\n",
    "## PGH Data Science (Technical) Interview\n",
    "\n",
    "The typical data science interview has several steps\n",
    "\n",
    "__Prior to onsite__\n",
    "1.  Technical phone screen / interview.  This type of interivew can go for 45 - 60 minutes and will involve either talking throw problems or having a web call / screen share where you (pseduo) code a solution and talk throw the solution.  These can cover anything.  \n",
    "2.  Take home projects.  Usually a data set is provided along with set of questions.  Some questions are well defined, while others are open ended.  Turn around varies from company to company.  \n",
    "3.  Coding challenges.  Solve problems in a format similar to hacker rank.  \n",
    "\n",
    "__Onsite__\n",
    "3.  Technical in person\n",
    "4.  Behavioral (pbbtt!!!)\n",
    "5.  Fit discussions\n",
    "4.  Role play - more geared towards statistics and interpretting output.  \n",
    "5.  General problem solving\n",
    "\n",
    "\n",
    "These questions have been curated across experiences I have had interviewing for positions (as interviewor and interviewee) in and related to data science or I just think are interesting (and applicable).  \n",
    "\n",
    "Some questions are tougher than others, but should not take an inordinate amount of time to solve / prototype.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%md\n",
    "# Problem 1\n",
    "\n",
    "Consider the problem of having an array of integers that goes from monotone decreasing to monotone increasing at some point in the array.  Your mission should you choose to accept it: Find the point, and the index at which the monotonicity changes and discuss complexity\n",
    "\n",
    "The actual way the question was presented to me in the interview\n",
    "\n",
    "$\\{x_n\\}_{n=1}^N$ is a sequence of integers s.t. $N < \\infty, \\exists \\; n \\in \\mathbb{N}$ such that $\\forall \\; i < n, x_{i} \\ge x_{i+1}$ and $\\forall \\; m > n, x_{m} \\le x_{m+1}$  \n",
    "\n",
    "\n",
    "What you should now\n",
    "1. loops\n",
    "2.  monotonicity - what this means.\n",
    "\n",
    "#### Considerations\n",
    "* The data WILL fit into main memory.\n",
    "* Suppose it is already instatiated and available via the variable x\n",
    "* The length of the array is n\n",
    "* We will take monotonicity to mean a function is monotone increasing if  $x_1 < x_2$ implies  $f(x_1)\\le f(x_2)$, whilst monotone decreasing would imply  $ f(x_1)\\ge f(x_2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%md\n",
    "\n",
    "## Solution Method 1\n",
    "A very straight forward solution would be to difference the array\n",
    "```\n",
    "for i in range(n)-1:\n",
    "  d = x[i+1] - x[i]\n",
    "  if d > 0:\n",
    "    print(i+1)\n",
    "    break\n",
    "```\n",
    "\n",
    "This certainly works right - We loop through our array and the first time that the difference between successive elements is greater than 0, we return the index.\n",
    "\n",
    "Next, the interview asks about the complexity. \n",
    "\n",
    "The complexity of this is  $O(N)$\n",
    "\n",
    "There is nothing wrong with this answer, be we can do much better\n",
    "\n",
    "## Solution Method 2\n",
    "If $n$ is the length of the array then let $l$ be half that lenght. Take the $l$ element and the $l+1$ element and see if the difference is positive. If the difference is positive, we'll search for the change point in the first $l+1$ elements, otherwise we'll search in the last $n-l$ elements.\n",
    "This method will have  $O(\\log n)$  comlexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mchangePoint\u001b[39m\n",
       "\u001b[36mx0\u001b[39m: \u001b[32mList\u001b[39m[\u001b[32mInt\u001b[39m] = \u001b[33mList\u001b[39m(\u001b[32m3\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m4\u001b[39m)\n",
       "\u001b[36mx1\u001b[39m: \u001b[32mList\u001b[39m[\u001b[32mInt\u001b[39m] = \u001b[33mList\u001b[39m(\u001b[32m10\u001b[39m, \u001b[32m8\u001b[39m, \u001b[32m7\u001b[39m, \u001b[32m7\u001b[39m, \u001b[32m5\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m8\u001b[39m)\n",
       "\u001b[36mx2\u001b[39m: \u001b[32mList\u001b[39m[\u001b[32mInt\u001b[39m] = \u001b[33mList\u001b[39m(\u001b[32m10\u001b[39m, \u001b[32m8\u001b[39m, \u001b[32m7\u001b[39m, \u001b[32m7\u001b[39m, \u001b[32m5\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m8\u001b[39m, \u001b[32m9\u001b[39m)\n",
       "\u001b[36mx3\u001b[39m: \u001b[32mList\u001b[39m[\u001b[32mInt\u001b[39m] = \u001b[33mList\u001b[39m(\u001b[32m10\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m7\u001b[39m)\n",
       "\u001b[36mx4\u001b[39m: \u001b[32mList\u001b[39m[\u001b[32mInt\u001b[39m] = \u001b[33mList\u001b[39m(\u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n",
       "\u001b[36mres0_6\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m2\u001b[39m\n",
       "\u001b[36mres0_7\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m7\u001b[39m\n",
       "\u001b[36mres0_8\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m7\u001b[39m\n",
       "\u001b[36mres0_9\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m2\u001b[39m\n",
       "\u001b[36mres0_10\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m2\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def changePoint(x: List[Int]): Int = {\n",
    "\n",
    "    def helper(xs: List[(Int, Int)]): Int = {\n",
    "        \n",
    "        if(xs.length == 2) { \n",
    "            if(xs(0)._1 - xs(1)._1 < 0) xs(1)._2\n",
    "            else xs(0)._2\n",
    "        }\n",
    "        else if(xs.length == 1) xs(0)._2\n",
    "        else {\n",
    "            val n = xs.length / 2\n",
    "            val d = xs(n-1)._1 - xs(n)._1\n",
    "            if(d > 0) helper(xs.drop(n))\n",
    "            else helper(xs.take(n+1))\n",
    "        }\n",
    "    }\n",
    "    helper(x zipWithIndex)\n",
    "}\n",
    "\n",
    "val x0 = List(3,2,3,4)\n",
    "val x1 = List(10,8,7,7,5, 1,0, 2, 2, 4, 8)\n",
    "val x2 = List(10,8,7,7,5, 1,0, 2, 2, 4, 8,9)\n",
    "val x3 = List(10,0,7)\n",
    "val x4 = List(2,1,2)\n",
    "\n",
    "changePoint(x0)\n",
    "changePoint(x1)\n",
    "changePoint(x2)\n",
    "changePoint(x3)\n",
    "changePoint(x4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%md\n",
    "## Problem 2\n",
    "\n",
    "Given a flat file containing the birth year and death year of 1 MM people, find the year with the most people living.  \n",
    "Assume that the file is a csv.  The following is an example of the first first line.  The first line contains field names\n",
    "\n",
    "| PersonID        | Birth_Year           | Death_Year  |\n",
    "| --| -- | -- |\n",
    "| 1 | 1890 | 1930|\n",
    "| 2 | 1900 | 1932|\n",
    "| 3 | 1912 | 1997|\n",
    "| ..| .. | .. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%md\n",
    "## Solution\n",
    "The general idea for the solution is to create a set of key value pairs, where the key is the year, and the value is an integer which will represent how many people were alive in the given key year.  For the purposes of this solution is is entirely reasonable to assume that a person is born on Jan 1 and pass on Dec 31.  \n",
    "\n",
    "\n",
    "In pseudo code\n",
    "```\n",
    "dictionary = {}\n",
    "for line in file:\n",
    "  id, birth, death = line.split(\",\")\n",
    "  for i in birth to death:\n",
    "    dictionary[i] += 1\n",
    "dictionary.sortByValue(\"descending\")[0]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 liveliest years\n",
      "(1965,3)\n",
      "(1966,3)\n",
      "(1967,3)\n",
      "(1968,3)\n",
      "(1969,3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mscala.collection.mutable.{Map => MutMap}\n",
       "    \n",
       "\u001b[39m\n",
       "defined \u001b[32mobject\u001b[39m \u001b[36mLiveliestYear\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import scala.collection.mutable.{Map => MutMap}\n",
    "    \n",
    "object LiveliestYear { \n",
    "    \n",
    "    val years = MutMap[Int, Int]()\n",
    "\n",
    "    def updateYearsMap(birth: Int, death: Int, yearsMap: MutMap[Int,Int]): Unit = { \n",
    "      for(i <- birth to death) {\n",
    "          yearsMap.update(i, yearsMap.getOrElse(i, 0) + 1)\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    def main(args: Array[String] = Array()) = {\n",
    "        val dispN = args(0).toInt\n",
    "        val data = List( List(1900, 1980), List(1890, 1972), List(1965, 1997) )\n",
    "        data.foreach{ case List(b,d) => updateYearsMap(b, d, years) }\n",
    "        println(s\"$dispN liveliest years\")\n",
    "        years.toList.sortWith{ _._1 < _._1 }.sortWith{ _._2 > _._2 }.take(dispN).foreach(println)\n",
    "    }\n",
    "    \n",
    "}\n",
    "\n",
    "LiveliestYear.main(Array(\"5\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%md\n",
    "# Problem 3\n",
    "\n",
    "You have a finite number of files.  Each file has one column of data, call this column X.  Each file is actually to big for main memory.  Considering the entire set of files as your dataset, calc the mean and standard deviation for X.  How to do this?  \n",
    "\n",
    "It would be helpful to know the following.  \n",
    "\n",
    "$\\mu = \\sum x / n$\n",
    "\n",
    "$\\sigma^2 =  \\sum (x - \\mu)^2 / (n-1)  $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%md\n",
    "## Solution Method 1 \n",
    "\n",
    "We will have to iterate over all the files and calculate the statistics piece-meal.  \n",
    "\n",
    "Pseudo code follows.  Your pseudo code should be readable!  \n",
    "\n",
    "```\n",
    "sumx = 0\n",
    "n = 0\n",
    "tss = 0 \n",
    "sum_centered_x = 0\n",
    "for file in files:\n",
    "  for line in file:     ## read each file line by line\n",
    "    sumx += line\n",
    "    n += 1\n",
    "mean = sumx / n\n",
    "for file in files:\n",
    "  for line in file:\n",
    "    tss += (line - mean)**2\n",
    "variance = tss / (n - 1)\n",
    "standard_deviation = sqrt(variance) \n",
    "```\n",
    "\n",
    "This is good, but can we do better?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%md\n",
    "## Solution Method 2\n",
    "\n",
    "Method 1 requires two passes at each file.  So with 100 files, we have 200 passes.  The main reason for this is because $\\mu$ is involved in the variance calculation.  We can break out our formulas and accomplish everything with one pass at the data.  \n",
    "\n",
    "$ \\sigma^2 = \\sum (x^2 - 2\\mu x + \\mu^2) / (n-1) $\n",
    "\n",
    "Notice that \n",
    "\n",
    "$(n-1)\\sigma^2 = \\sum (x - \\mu)^2 = \\left(\\sum x^2\\right) - n\\mu^2$\n",
    "\n",
    "This lets us do \n",
    "\n",
    "```\n",
    "sumx = 0\n",
    "sumx2 = 0\n",
    "n = 0\n",
    "for file in files:\n",
    "  for line in file:\n",
    "    sumx += line\n",
    "    sumx2 += line**2\n",
    "    n += 1\n",
    "mean = sumx / n\n",
    "variance = sumx2 - n*(mean)**2\n",
    "variance /= n-1\n",
    "standard_deviation = sqrt(variance) \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sumx: 1546.72, sumx2: 17194.32, n:  165\n",
      "sumx: 2027.78, sumx2: 23601.64, n:  199\n",
      "sumx: 1328.59, sumx2: 14821.55, n:  138\n",
      "sumx:   78.29, sumx2:   990.13, n:    7\n",
      "sumx: 1746.89, sumx2: 20912.79, n:  170\n",
      "sumx:   15.38, sumx2:   119.55, n:    2\n",
      "sumx: 1651.75, sumx2: 19684.54, n:  162\n",
      "sumx:  529.49, sumx2:  6171.81, n:   52\n",
      "sumx:  964.40, sumx2: 11569.75, n:   94\n",
      "sumx:  427.44, sumx2:  5076.11, n:   40\n",
      "total mean => 10.026\n",
      "total std dev => 4.031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mjava.io.PrintWriter\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.util.Random.nextGaussian\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.math.{pow, sqrt}\n",
       "\n",
       "\u001b[39m\n",
       "defined \u001b[32mobject\u001b[39m \u001b[36mDescStats\u001b[39m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import java.io.PrintWriter\n",
    "import scala.util.Random.nextGaussian\n",
    "import scala.math.{pow, sqrt}\n",
    "\n",
    "object DescStats {\n",
    "    \n",
    "    def main(args: Array[String] = Array()) = {\n",
    "        \n",
    "        // generate data\n",
    "        for(i <- 0 until 10) { \n",
    "        val stddev = 4d  \n",
    "        val mean = 10d  \n",
    "        val pw = new PrintWriter(s\"file$i.txt\")\n",
    "        val records = (scala.util.Random.nextDouble * 200).toInt\n",
    "        for(i <- 0 until records) pw.write( (stddev*nextGaussian + mean) + \"\\n\")\n",
    "        pw.close\n",
    "        }\n",
    "\n",
    "        import java.io.File\n",
    "        val f = new File(\".\")\n",
    "        val fs = f.listFiles.filter{ _.toString.contains(\".txt\") };\n",
    "\n",
    "        def helper(f: File): (Double, Double, Double) = { \n",
    "            val src = scala.io.Source.fromFile(f)\n",
    "            val data = src.getLines\n",
    "            val map = data.map{ _.toDouble }.map{ value => (value, value*value, 1d )}\n",
    "            val reduce = map.foldLeft( (0d, 0d, 0d) ){ (x, y) => (x._1 + y._1, x._2 + y._2, x._3 + y._3)}\n",
    "            src.close\n",
    "            reduce\n",
    "        }\n",
    "\n",
    "        fs.map(helper).foreach{ \n",
    "            case (sumx, sumx2, n) => \n",
    "            println(f\"sumx: ${sumx}%7.2f, sumx2: ${sumx2}%8.2f, n: $n%4.0f\")\n",
    "        }\n",
    "\n",
    "        val (sumX, sumX2, n) = fs.map(helper).foldLeft( (0d,0d,0d) ){ (x,y) => (x._1 + y._1, x._2 + y._2, x._3 + y._3 )}\n",
    "\n",
    "        val mean = sumX / n\n",
    "        val variance = (sumX2 - n * pow(mean, 2))/(n-1)\n",
    "        println(f\"total mean => ${mean}%2.3f\\ntotal std dev => ${sqrt(variance)}%2.3f\")\n",
    "\n",
    "        fs.foreach{ _.delete }\n",
    "    }\n",
    "}\n",
    "\n",
    "DescStats.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%md\n",
    "# Problem 4 \n",
    "\n",
    "One hot encoding\n",
    "Convert\n",
    "\n",
    "|id|\tcity|\n",
    "|--|--|\n",
    "|1|\tboston|\n",
    "|2\t|nyc|\n",
    "|3\t|tokyo|\n",
    "|4\t|boston|\n",
    "|5\t|tokyo|\n",
    "|6\t|tokyo|\n",
    "|..|\t..|\n",
    "to\n",
    "\n",
    "|id|\tohe|\n",
    "|--|--|\n",
    "|1\t|[1,0,0]|\n",
    "|2\t|[0,1,0]|\n",
    "|3\t|[0,0,1]|\n",
    "|4\t|[1,0,0]|\n",
    "|5\t|[0,0,1]|\n",
    "|6\t|[0,0,1]|\n",
    "|..|\t..|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%md\n",
    "## Solution \n",
    "\n",
    "\n",
    "### What you should now\n",
    "* loops\n",
    "* dictionary\n",
    "* concept of one hot encoding\n",
    "\n",
    "\n",
    "### Considerations\n",
    "1. How many unique cities are in the file - this will certainly impact the length of our one hot encoded vector\n",
    "2. Are ids unique? For example, is id 1 repeated anywhere else in the data set?\n",
    "3. Outline of the approach.\n",
    "4. We'll assume that we don't know the total number of distinct cities in the dataset. Furthermore, the ids are unique.\n",
    "\n",
    "\n",
    "create a Set of all cities. Ordering will not mater.\n",
    "Store the size of this set, denote this as  n\n",
    "\n",
    "our one hot encoder is a function that maps the cities in our dataset to a sequence of ones and zeros.  The one occurs in at the index of the vector that coincides with the index of the city in the set.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%md\n",
    "### Method 1\n",
    "Assume that it is known how many different cities are in the dataset, for our purposes, 3 (boston, tokyo and nyc).\n",
    "create a Set of all cities. Ordering will not mater.\n",
    "Store the size of this set, denote this as  n\n",
    "\n",
    "our one hot encoder is a function  $ohe:cities \\to \\{0,1\\}^n$ with $\\{0,1\\}^n$ a binary sequence of length $n$, with $1$ in the $i^{th}$ position and $0$ elsewhere.  \n",
    "\n",
    "```::scala\n",
    "val citiesMap = Set(cities:_*).zipWithIndex.toMap\n",
    "val numCities = citiesMap.size\n",
    "val oheCities = cities.map{\n",
    "  city => (citiesMap(city), numCities)\n",
    "}.map{\n",
    "  elem =>\n",
    "  val ohe = Array.fill(elem._2){0d}\n",
    "  ohe(elem._1) = 1d\n",
    "  ohe\n",
    "}    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boston \t, [1.0,0.0,0.0]\n",
      "nyc \t, [0.0,1.0,0.0]\n",
      "tokyo \t, [0.0,0.0,1.0]\n",
      "boston \t, [1.0,0.0,0.0]\n",
      "tokyo \t, [0.0,0.0,1.0]\n",
      "tokyo \t, [0.0,0.0,1.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mobject\u001b[39m \u001b[36mOheMethod1\u001b[39m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "object OheMethod1 {\n",
    "    \n",
    "    def main(args: Array[String] = Array()) = {\n",
    "        val cities = Array(\n",
    "        \"boston\",\n",
    "        \"nyc\",\n",
    "        \"tokyo\",\n",
    "        \"boston\",\n",
    "        \"tokyo\",\n",
    "        \"tokyo\")\n",
    "\n",
    "        val citiesMap = Set(cities:_*).zipWithIndex.toMap\n",
    "        val numCities = citiesMap.size\n",
    "        val oheCities = cities.map{\n",
    "          city => (citiesMap(city), numCities)\n",
    "        }.map{\n",
    "          elem =>\n",
    "          val ohe = Array.fill(elem._2){0d}\n",
    "          ohe(elem._1) = 1d\n",
    "          ohe\n",
    "        }\n",
    "\n",
    "        cities.zip(oheCities).foreach {case( c, o) => println(s\"${c} \\t, ${o.mkString(\"[\",\",\",\"]\")}\") }\n",
    "    }\n",
    "}\n",
    "OheMethod1.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%md\n",
    "### Method 2\n",
    "The above solution is good, but suppose that the dataset is too big for main memory, therefore, we wouldn't be able to create the city Set as we did previously. We can handle this by making a few small changes to the code\n",
    "1. start with a mutable map with string key and integer value.\n",
    "2. initialize a counter (we use an java AtomicInteger to take advantage of reference)\n",
    "3. iterate over the data. If a city is not in your map, increment the counter and add the city as key and the counter as value.\n",
    "4. iterate once more to create the one hot encoded vector\n",
    "\n",
    "\n",
    "```::scala\n",
    "val numClasses = new AtomicInteger\n",
    "val citiesMutMap = MutMap[String, Int]()\n",
    "val oheCities = cities.map{ city =>\n",
    "  if(citiesMutMap contains city) {\n",
    "    (numClasses, citiesMutMap(city))\n",
    "  } else {\n",
    "    citiesMutMap.update(city, numClasses.getAndAdd(1) )\n",
    "    (numClasses, citiesMutMap(city))\n",
    "  }\n",
    "}.map{\n",
    "  case(numClasses, cityIndex)  =>\n",
    "    val ohe = Array.fill(numClasses.get){0d}\n",
    "    ohe(index) = 1d\n",
    "    ohe\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boston \t, [1.0,0.0,0.0]\n",
      "nyc \t, [0.0,1.0,0.0]\n",
      "tokyo \t, [0.0,0.0,1.0]\n",
      "boston \t, [1.0,0.0,0.0]\n",
      "tokyo \t, [0.0,0.0,1.0]\n",
      "tokyo \t, [0.0,0.0,1.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mjava.util.concurrent.atomic.AtomicInteger\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.collection.mutable.{Map => MutMap}\n",
       "\n",
       "\u001b[39m\n",
       "defined \u001b[32mobject\u001b[39m \u001b[36mOheMethod2\u001b[39m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import java.util.concurrent.atomic.AtomicInteger\n",
    "import scala.collection.mutable.{Map => MutMap}\n",
    "\n",
    "object OheMethod2 { \n",
    "\n",
    "    def main(args: Array[String] = Array()) = { \n",
    "        val cities = Array(\n",
    "          \"boston\",\n",
    "          \"nyc\",\n",
    "          \"tokyo\",\n",
    "          \"boston\",\n",
    "          \"tokyo\",\n",
    "          \"tokyo\")\n",
    "        val numClasses = new AtomicInteger\n",
    "        val citiesMutMap = MutMap[String, Int]()\n",
    "        val oheCities = cities.map{ city =>\n",
    "          if(citiesMutMap contains city) {\n",
    "            (numClasses, citiesMutMap(city))\n",
    "          } else {\n",
    "            citiesMutMap.update(city, numClasses.getAndAdd(1) )\n",
    "            (numClasses, citiesMutMap(city))\n",
    "          }\n",
    "        }.map{\n",
    "            case(numClasses, cityIndex)  =>\n",
    "            val ohe = Array.fill(numClasses.get){0d}\n",
    "            ohe(cityIndex) = 1d\n",
    "            ohe\n",
    "        }\n",
    "\n",
    "        (cities zip oheCities).foreach{ case(c,i) => println(s\"${c} \\t, ${i.mkString(\"[\",\",\",\"]\")}\")}\n",
    "    }\n",
    "}\n",
    "\n",
    "OheMethod2.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%md\n",
    "# Problem 4 \n",
    "One hot encoding\n",
    "harder version\n",
    "Data - You are interested in predicting whether a user will see a movie based on the movies they have seen in the theatre in the last year. The dataset has two columns, one for the user id and one for the movie they saw (a movie name). The data is as follows\n",
    "\n",
    "User\t|movie\n",
    "--|--\n",
    "1|\tJumani\n",
    "1|\tA Quiet Place\n",
    "1|\tGame Night\n",
    "2|\tJurasic World\n",
    "2|\tThe Last Jedi\n",
    "2|\tHereditary\n",
    "2|\tCoco\n",
    "3|\tMother\n",
    "..|..\n",
    "And we need to convert it to something like\n",
    "\n",
    "user|\tm1|\tm2|\tm3|\tm4|\tm5|\tm6|\tm7|\tm8|\t..|\tmn|\n",
    "--  |--   |-- |-- |-- |-- |-- |-- |-- |-- |--|\n",
    "1|\t1|\t1|\t0|\t0|\t1|\t0|\t0|\t0|\t..|\t0|\n",
    "2|\t0|\t0|\t1|\t1|\t0|\t0|\t1|\t1|\t..|\t0|\n",
    "3|\t0|\t0|\t0|\t0|\t0|\t0|\t0|\t0|\t..|\t0|\n",
    "..|..| ..| ..| ..| ..| ..| ..| ..| ..|.. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%md\n",
    "## Solution \n",
    "\n",
    "### Considerations\n",
    "1. How many unique movies are in the file\n",
    "2.  Can a user movie combination appear more than once (I know a guy that saw fire fly in the theather 4 times)\n",
    "3. Is the data sorted in any fashion\n",
    "\n",
    "### What you should now\n",
    "1. Reading files\n",
    "2. loops\n",
    "3. dictionary\n",
    "4. storing sparse data\n",
    "5. writing classes\n",
    "\n",
    "Approach \n",
    "\n",
    "* Do not assume the data is sorted.\n",
    "* Assume the user movie combination is unique\n",
    "\n",
    "We'll initialize a variable c to keep track of the number of unique movies in the data set, then convert our dataset to key value pairs where each key is a user id and each value is an array containing the movie id which the user has seen. These arrays will then be convert to a sparse vector, for us this will just be a tuple of type  (Int, Vector[Int], Vector[Double]). The first element in the tuple is the length of the vector, the second element will be the indices which are non-zero, while the third element will contain the corresponding non-zero values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,SparseVector(8,Vector(3, 4, 5, 6),Vector(1.0, 1.0, 1.0, 1.0)))\n",
      "(1,SparseVector(8,Vector(0, 1, 2),Vector(1.0, 1.0, 1.0)))\n",
      "(3,SparseVector(8,Vector(7),Vector(1.0)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mscala.collection.mutable.{Map=>MutMap}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.util.concurrent.atomic.AtomicInteger\n",
       "\n",
       "// SparseVector class\n",
       "\u001b[39m\n",
       "defined \u001b[32mclass\u001b[39m \u001b[36mSparseVector\u001b[39m\n",
       "defined \u001b[32mobject\u001b[39m \u001b[36mOheHarder\u001b[39m"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// imports \n",
    "import scala.collection.mutable.{Map=>MutMap}\n",
    "import java.util.concurrent.atomic.AtomicInteger\n",
    "\n",
    "// SparseVector class\n",
    "case class SparseVector(length: Int, indices: Vector[Int], values: Vector[Double])\n",
    "// import data\n",
    "\n",
    "object OheHarder {\n",
    "    def main(args: Array[String] = Array()) = {\n",
    "        val path = sys.env(\"HOME\") + \"/Desktop/pgh data science/movies.csv\"\n",
    "        val src = scala.io.Source.fromFile(path)\n",
    "        val data = src.getLines.map{ _.split(\",\")}\n",
    "        data.next\n",
    "\n",
    "        val users = MutMap[String, Vector[Int]]()  // create a dictionary of users\n",
    "        val movies = MutMap[String, Int]()         // create a dictionary of movies\n",
    "        val c = new AtomicInteger                  \n",
    "\n",
    "        data.foreach{ line => \n",
    "          val Array(user, movie) = line\n",
    "          if(!movies.contains(movie)) { \n",
    "              movies.update(movie, c.getAndAdd(1))  \n",
    "          }\n",
    "          val movieId = movies(movie)\n",
    "          if(users.contains(user)) {\n",
    "              users.update(user, movieId +: users(user))\n",
    "          } else { \n",
    "              users.update(user, Vector(movieId))\n",
    "          }\n",
    "        }\n",
    "        for(user <- users.keys) { \n",
    "           users.update( user, users(user).sortWith(_ < _))\n",
    "        }\n",
    "        val ohe = users.map{ case(user, movies) => (user, SparseVector(c.get, movies, Vector.fill(movies.length){1d}))}\n",
    "        ohe.foreach(println)\n",
    "    }\n",
    "}\n",
    "\n",
    "OheHarder.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%md\n",
    "\n",
    "## Problem 5\n",
    "\n",
    "$Z$ is a random $Bernoulli(1-p)$ variable\n",
    "\n",
    "$Y$ is a random discrete $Uniform[0, N-1]$ variable  if $Z = 1$, otherwise $Y$ is 0\n",
    "\n",
    "Calculate \n",
    "1.  The PDF for $Y$\n",
    "2.  The expected value of $Z$ given $Y$ is zero.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%md\n",
    "\n",
    "### Solution\n",
    "\n",
    "To complete this you should know the following \n",
    "1.  PDF (probability density function)\n",
    "2.  Calculating expected values\n",
    "3.  Conditional probabilities\n",
    "\n",
    "The first part is fairly straight forward.  \n",
    "\n",
    "A discrete Uniform[0,N-1] has pdf $1 / N$.  A Bernoulli(1-p) RV $Y$ is 1 with probability 1-p and 0 with probability p.  We may write this succintly as $ p^{1-Y}(1-p)^{Y} $ \n",
    "\n",
    "Now $P(Y = 0) = P(Y = 0 \\cap Z = 0) + P(Y = 0 \\cap Z = 1) = p + 1/n (1-p) $\n",
    "\n",
    "Next, take $i > 0$$, then $P(Y = i) = P(Y = i \\cap Z = 0) + P(Y = i \\cap Z = 1) = 0 + \\frac{1}{N}(1 - p)$\n",
    "\n",
    " \n",
    "Lastly, $ \\mathbb{E}[Z | Y = 0] = \\sum_{z} z\\cdot p(Z = z | Y = 0) = p(Z = 1 | Y = 0) = P(Z = 1 \\cap Y = 0) / P( Y = 0) = \\frac{p}{p + (1-p)/N}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%md\n",
    "# Problem 6 \n",
    "\n",
    "You work for an e-commerce site and you have 1MM customers. Marketing is toying with the idea of introducing a reward card. They design the following test to decide whether a reward card is worth it.\n",
    "\n",
    "They randomly sample 10% of the customer base to conduct the experiment and the remaining 90% is used as a control group. This 10% will be offered the reward card.\n",
    "Of the 10%, only 5% sign up. Of those who signed up, you see them spending \\$130 per visit, while those who don't spend \\$98 per visit.\n",
    "\n",
    "The control group has average spend of \\$99 per trip\n",
    "\n",
    "If the rewards cost \\$10 per customer that signs up and there is are fixed costs of \\$5K, would you recommend rolling out the reward card?\n",
    "\n",
    "P.S. this is a poor design because I made it up :) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%md\n",
    "### Solution \n",
    "\n",
    "Based on the construction of test and control groups, we would expect that 5% of customers in the control group would probably have signed up for the card if they were offered - so any difference in their average spend vs the test group will be attributed to the rewards card.\n",
    "\n",
    "We can assume that 95 percent of the Control group is identical to the 95% of the test group who didn't sign up for the card, so we'll assume they have a similar spend of $98 per vist.\n",
    "\n",
    "Thus the average spend of the control group is \\\\(99=0.95\\cdot 98+0.05 \\cdot x\\\\), where  \\\\(x\\\\) is the 5% of the control that we figure would sign up for the card having been offered. Thus,  \\\\(x=$118\\\\).  This means that the rewards card generated $12 of additional spend per customer that signed up.\n",
    "\n",
    "Now we must account for the cost. We had 5,000 people sign up, which resulted in an incremental spend of \\$12 per person.\n",
    "The costs the company incurs is \\$5,000 fix cost and \\$10 variable cost, we end up at making \\$5,000 at the end of the expermiment $(12−10)⋅5000−5000=5000$. We should consider rolling out the reward program!!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%md\n",
    "\n",
    "# Problem 8\n",
    "\n",
    "You have two matrices, call them \\\\(X\\\\) and \\\\(Y\\\\).  Matrix \\\\(X\\\\) has \\\\(m\\\\) rows and \\\\(n\\\\) columns, while \\\\(Y\\\\) has \\\\(n\\\\) columns and \\\\(l\\\\) rows.  Both matrices are stored in a SQL database.  For our purpose suppose that the matrices are stored in table `x` and table `y`.  The tables have 3 columns each:\n",
    "\n",
    "1. Row - index of the row for the corresponding value\n",
    "2. Column - index of the column for the corresponding value\n",
    "3. Value - the value\n",
    "\n",
    "Compute \\\\(XY\\\\) by writing a SQL query\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%md\n",
    "### Solution \n",
    "\n",
    "Matrix mutliplication between \\\\(X\\\\) and \\\\(Y\\\\) are defined is defined as \n",
    "\n",
    "\\\\(Z_{i,j} = \\sum_{k} X_{i,k}Y_{k,j}\\\\)\n",
    "\n",
    "The query should be written to join `x` and `y` on `x`'s column index and `y`'s row index.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cmd6.sc:6: not found: value sc\n",
      "val x = sc.parallelize (for{ i <- 0 to m; \n",
      "        ^cmd6.sc:8: not found: value sc\n",
      "val y = sc.parallelize (for{ i <- 0 to n; \n",
      "        ^"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "Compilation Failed"
     ]
    }
   ],
   "source": [
    "// won't work\n",
    "// generate data \n",
    "case class MatrixElement(row: Int, column: Int, value: Double)\n",
    "import scala.util.Random.nextGaussian\n",
    "val m = 3\n",
    "val n = 2\n",
    "val l = 1\n",
    "val x = sc.parallelize (for{ i <- 0 to m; \n",
    "     j <- 0 to n} yield MatrixElement(i,j,nextGaussian)).toDF\n",
    "val y = sc.parallelize (for{ i <- 0 to n; \n",
    "     j <- 0 to l} yield MatrixElement(i,j,nextGaussian)).toDF\n",
    "x.createOrReplaceTempView(\"x\")\n",
    "y.createOrReplaceTempView(\"y\")\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%sql\n",
    "'''\n",
    "select x.row, y.column, sum(x.value * y.value) as value\n",
    "from x inner join y\n",
    "on x.column = y.row \n",
    "group by x.row, y.column\n",
    "order by 1, 2\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala211",
   "nbconvert_exporter": "script",
   "pygments_lexer": "scala",
   "version": "2.11.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
