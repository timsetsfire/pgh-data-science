{"paragraphs":[{"text":"%md\n## PGH Data Science (Technical) Interview\n\nThe typical data science interview has several steps\n\n__Prior to onsite__\n1.  Technical phone screen / interview.  This type of interivew can go for 45 - 60 minutes and will involve either talking throw problems or having a web call / screen share where you (pseduo) code a solution and talk throw the solution.  These can cover anything.  \n2.  Take home projects.  Usually a data set is provided along with set of questions.  Some questions are well defined, while others are open ended.  Turn around varies from company to company.  \n3.  Coding challenges.  Solve problems in a format similar to hacker rank.  \n\n__Onsite__\n3.  Technical in person\n4.  Behavioral (pbbtt!!!)\n5.  Fit discussions\n4.  Role play - more geared towards statistics and interpretting output.  \n5.  General problem solving\n\n\nThese questions have been curated across experiences I have had interviewing for positions (as interviewor and interviewee) in and related to data science or I just think are interesting (and applicable).  \n\nSome questions are tougher than others, but should not take an inordinate amount of time to solve / prototype.  ","user":"anonymous","dateUpdated":"2018-07-09T23:17:11-0400","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>PGH Data Science (Technical) Interview</h2>\n<p>The typical data science interview has several steps</p>\n<p><strong>Prior to onsite</strong><br/>1. Technical phone screen / interview. This type of interivew can go for 45 - 60 minutes and will involve either talking throw problems or having a web call / screen share where you (pseduo) code a solution and talk throw the solution. These can cover anything.<br/>2. Take home projects. Usually a data set is provided along with set of questions. Some questions are well defined, while others are open ended. Turn around varies from company to company.<br/>3. Coding challenges. Solve problems in a format similar to hacker rank. </p>\n<p><strong>Onsite</strong><br/>3. Technical in person<br/>4. Behavioral (pbbtt!!!)<br/>5. Fit discussions<br/>4. Role play - more geared towards statistics and interpretting output.<br/>5. General problem solving</p>\n<p>These questions have been curated across experiences I have had interviewing for positions (as interviewor and interviewee) in and related to data science or I just think are interesting (and applicable). </p>\n<p>Some questions are tougher than others, but should not take an inordinate amount of time to solve / prototype.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1531192624092_-1000538014","id":"20180706-212456_538781425","dateCreated":"2018-07-09T23:17:04-0400","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:42780","dateFinished":"2018-07-09T23:17:11-0400","dateStarted":"2018-07-09T23:17:11-0400"},{"text":"%md\n# Problem 1\n\nConsider the problem of having an array of integers that goes from monotone decreasing to monotone increasing at some point in the array.  Your mission should you choose to accept it: Find the point, and the index at which the monotonicity changes and discuss complexity\n\nThe actual way the question was presented to me in the interview\n\n\\\\(\\\\{x_n\\\\}_{n=1}^N\\\\) is a sequence of integers s.t. \\\\(N < \\infty\\\\, \\exists \\; n \\in \\mathbb{N}\\\\) such that \\\\(\\forall \\; i < n, x_{i} \\ge x_{i+1}\\\\) and \\\\(\\forall \\; m > n, x_{m} \\le x_{m+1}\\\\)  \n\n\nWhat you should now\n1. loops\n2.  monotonicity - what this means.\n\n#### Considerations\n* The data WILL fit into main memory.\n* Suppose it is already instatiated and available via the variable x\n* The length of the array is n\n* We will take monotonicity to mean a function is monotone increasing if  \\\\(x_1 < x_2\\\\) implies  \\\\(f(x_1)\\le f(x_2)\\\\), whilst monotone decreasing would imply  \\\\( f(x_1)\\ge f(x_2)\\\\)","user":"anonymous","dateUpdated":"2018-07-09T23:17:04-0400","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Problem 1</h1>\n<p>Consider the problem of having an array of integers that goes from monotone decreasing to monotone increasing at some point in the array. Your mission should you choose to accept it: Find the point, and the index at which the monotonicity changes and discuss complexity</p>\n<p>The actual way the question was presented to me in the interview</p>\n<p>\\(\\{x_n\\}_{n=1}^N\\) is a sequence of integers s.t. \\(N &lt; \\infty\\, \\exists \\; n \\in \\mathbb{N}\\) such that \\(\\forall \\; i &lt; n, x_{i} \\ge x_{i+1}\\) and \\(\\forall \\; m &gt; n, x_{m} \\le x_{m+1}\\) </p>\n<p>What you should now<br/>1. loops<br/>2. monotonicity - what this means.</p>\n<h4>Considerations</h4>\n<ul>\n  <li>The data WILL fit into main memory.</li>\n  <li>Suppose it is already instatiated and available via the variable x</li>\n  <li>The length of the array is n</li>\n  <li>We will take monotonicity to mean a function is monotone increasing if \\(x_1 &lt; x_2\\) implies \\(f(x_1)\\le f(x_2)\\), whilst monotone decreasing would imply \\( f(x_1)\\ge f(x_2)\\)</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1531192624094_1150042856","id":"20180706-213218_1550796375","dateCreated":"2018-07-09T23:17:04-0400","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:42781"},{"text":"%md\n\n## Solution Method 1\nA very straight forward solution would be to difference the array\n```\nfor i in range(n)-1:\n  d = x[i+1] - x[i]\n  if d > 0:\n    print(i+1)\n    break\n```\n\nThis certainly works right - We loop through our array and the first time that the difference between successive elements is greater than 0, we return the index.\n\nNext, the interview asks about the complexity. \n\nThe complexity of this is  \\\\(O(N)\\\\)\n\nThere is nothing wrong with this answer, be we can do much better\n\n## Solution Method 2\nIf \\\\(n\\\\) is the length of the array then let \\\\(l\\\\) be half that lenght. Take the \\\\(l\\\\) element and the \\\\(l+1\\\\) element and see if the difference is positive. If the difference is positive, we'll search for the change point in the first \\\\(l+1\\\\) elements, otherwise we'll search in the last \\\\(n-l\\\\) elements.\nThis method will have  \\\\(O(\\log n)\\\\)  comlexity.","user":"anonymous","dateUpdated":"2018-07-09T23:25:35-0400","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Solution Method 1</h2>\n<p>A very straight forward solution would be to difference the array</p>\n<pre><code>for i in range(n)-1:\n  d = x[i+1] - x[i]\n  if d &gt; 0:\n    print(i+1)\n    break\n</code></pre>\n<p>This certainly works right - We loop through our array and the first time that the difference between successive elements is greater than 0, we return the index.</p>\n<p>Next, the interview asks about the complexity. </p>\n<p>The complexity of this is \\(O(N)\\)</p>\n<p>There is nothing wrong with this answer, be we can do much better</p>\n<h2>Solution Method 2</h2>\n<p>If \\(n\\) is the length of the array then let \\(l\\) be half that lenght. Take the \\(l\\) element and the \\(l+1\\) element and see if the difference is positive. If the difference is positive, we&rsquo;ll search for the change point in the first \\(l+1\\) elements, otherwise we&rsquo;ll search in the last \\(n-l\\) elements.<br/>This method will have \\(O(\\log n)\\) comlexity.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1531192624095_-1995204110","id":"20180706-215145_642233428","dateCreated":"2018-07-09T23:17:04-0400","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:42782"},{"text":"def changePoint(x: List[Int]): Int = {\n\n    def helper(xs: List[(Int, Int)]): Int = {\n        \n        if(xs.length == 2) { \n            if(xs(0)._1 - xs(1)._1 < 0) xs(1)._2\n            else xs(0)._2\n        }\n        else if(xs.length == 1) xs(0)._2\n        else {\n            val n = xs.length / 2\n            val d = xs(n-1)._1 - xs(n)._1\n            if(d > 0) helper(xs.drop(n))\n            else helper(xs.take(n+1))\n        }\n    }\n    helper(x zipWithIndex)\n}\n\nval x0 = List(3,2,3,4)\nval x1 = List(10,8,7,7,5, 1,0, 2, 2, 4, 8)\nval x2 = List(10,8,7,7,5, 1,0, 2, 2, 4, 8,9)\nval x3 = List(10,0,7)\nval x4 = List(2,1,2)\n\nchangePoint(x0)\nchangePoint(x1)\nchangePoint(x2)\nchangePoint(x3)\nchangePoint(x4)","user":"anonymous","dateUpdated":"2018-07-09T23:17:04-0400","config":{"tableHide":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"warning: there was one feature warning; re-run with -feature for details\nchangePoint: (x: List[Int])Int\nx0: List[Int] = List(3, 2, 3, 4)\nx1: List[Int] = List(10, 8, 7, 7, 5, 1, 0, 2, 2, 4, 8)\nx2: List[Int] = List(10, 8, 7, 7, 5, 1, 0, 2, 2, 4, 8, 9)\nx3: List[Int] = List(10, 0, 7)\nx4: List[Int] = List(2, 1, 2)\nres81: Int = 2\nres82: Int = 7\nres83: Int = 7\nres84: Int = 2\nres85: Int = 2\n"}]},"apps":[],"jobName":"paragraph_1531192624095_385459975","id":"20180706-212341_447968827","dateCreated":"2018-07-09T23:17:04-0400","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:42784"},{"text":"%md\n## Problem 2\n\nGiven a flat file containing the birth year and death year of 1 MM people, find the year with the most people living.  \nAssume that the file is a csv.  The following is an example of the first first line.  The first line contains field names\n\n| PersonID        | Birth_Year           | Death_Year  |\n| --| -- | -- |\n| 1 | 1890 | 1930|\n| 2 | 1900 | 1932|\n| 3 | 1912 | 1997|\n| ..| .. | .. |\n","user":"anonymous","dateUpdated":"2018-07-09T23:17:04-0400","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Problem 2</h2>\n<p>Given a flat file containing the birth year and death year of 1 MM people, find the year with the most people living.<br/>Assume that the file is a csv. The following is an example of the first first line. The first line contains field names</p>\n<table>\n  <thead>\n    <tr>\n      <th>PersonID </th>\n      <th>Birth_Year </th>\n      <th>Death_Year </th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1 </td>\n      <td>1890 </td>\n      <td>1930</td>\n    </tr>\n    <tr>\n      <td>2 </td>\n      <td>1900 </td>\n      <td>1932</td>\n    </tr>\n    <tr>\n      <td>3 </td>\n      <td>1912 </td>\n      <td>1997</td>\n    </tr>\n    <tr>\n      <td>..</td>\n      <td>.. </td>\n      <td>.. </td>\n    </tr>\n  </tbody>\n</table>\n</div>"}]},"apps":[],"jobName":"paragraph_1531192624095_861948199","id":"20180706-215106_808534016","dateCreated":"2018-07-09T23:17:04-0400","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:42785"},{"text":"%md\n## Solution\nThe general idea for the solution is to create a set of key value pairs, where the key is the year, and the value is an integer which will represent how many people were alive in the given key year.  For the purposes of this solution is is entirely reasonable to assume that a person is born on Jan 1 and pass on Dec 31.  \n\n\nIn pseudo code\n```\ndictionary = {}\nfor line in file:\n  id, birth, death = line.split(\",\")\n  for i in birth to death:\n    dictionary[i] += 1\ndictionary.sortByValue(\"descending\")[0]\n```","user":"anonymous","dateUpdated":"2018-07-09T23:25:13-0400","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Solution</h2>\n<p>The general idea for the solution is to create a set of key value pairs, where the key is the year, and the value is an integer which will represent how many people were alive in the given key year. For the purposes of this solution is is entirely reasonable to assume that a person is born on Jan 1 and pass on Dec 31. </p>\n<p>In pseudo code</p>\n<pre><code>dictionary = {}\nfor line in file:\n  id, birth, death = line.split(&quot;,&quot;)\n  for i in birth to death:\n    dictionary[i] += 1\ndictionary.sortByValue(&quot;descending&quot;)[0]\n</code></pre>\n</div>"}]},"apps":[],"jobName":"paragraph_1531192624096_-637821196","id":"20180706-215242_323558571","dateCreated":"2018-07-09T23:17:04-0400","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:42786"},{"text":"%spark\nimport scala.collection.mutable.{Map => MutMap}\n    \nobject LiveliestYear { \n    \n    val years = MutMap[Int, Int]()\n\n    def updateYearsMap(birth: Int, death: Int, yearsMap: MutMap[Int,Int]): Unit = { \n      for(i <- birth to death) {\n          yearsMap.update(i, yearsMap.getOrElse(i, 0) + 1)\n      }\n    }\n    \n    def main(args: Array[String] = Array()) = {\n        val dispN = args(0).toInt\n        val data = List( List(1900, 1980), List(1890, 1972), List(1965, 1997) )\n        data.foreach{ case List(b,d) => updateYearsMap(b, d, years) }\n        println(s\"$dispN liveliest years\")\n        years.toList.sortWith{ _._1 < _._1 }.sortWith{ _._2 > _._2 }.take(dispN).foreach(println)\n    }\n    \n}\n\nLiveliestYear.main(Array(\"5\"))\n","user":"anonymous","dateUpdated":"2018-07-09T23:17:04-0400","config":{"tableHide":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import scala.collection.mutable.{Map=>MutMap}\ndefined object LiveliestYear\n5 liveliest years\n(1965,3)\n(1966,3)\n(1967,3)\n(1968,3)\n(1969,3)\n"}]},"apps":[],"jobName":"paragraph_1531192624096_2119491267","id":"20180706-215342_1162108673","dateCreated":"2018-07-09T23:17:04-0400","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:42788"},{"text":"%md\n# Problem 3\n\nYou have a finite number of files.  Each file has one column of data, call this column X.  Each file is actually to big for main memory.  Considering the entire set of files as your dataset, calc the mean and standard deviation for X.  How to do this?  \n\nIt would be helpful to know the following.  \n\n\\\\(\\mu = \\sum x / n\\\\)\n\n\\\\(\\sigma^2 =  \\sum (x - \\mu)^2 / (n-1)  \\\\)\n","user":"anonymous","dateUpdated":"2018-07-09T23:17:04-0400","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Problem 3</h1>\n<p>You have a finite number of files. Each file has one column of data, call this column X. Each file is actually to big for main memory. Considering the entire set of files as your dataset, calc the mean and standard deviation for X. How to do this? </p>\n<p>It would be helpful to know the following. </p>\n<p>\\(\\mu = \\sum x / n\\)</p>\n<p>\\(\\sigma^2 = \\sum (x - \\mu)^2 / (n-1) \\)</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1531192624096_-528535282","id":"20180706-220256_2003234915","dateCreated":"2018-07-09T23:17:04-0400","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:42789"},{"text":"%md\n## Solution Method 1 \n\nWe will have to iterate over all the files and calculate the statistics piece-meal.  \n\nPseudo code follows.  Your pseudo code should be readable!  \n\n```\nsumx = 0\nn = 0\ntss = 0 \nsum_centered_x = 0\nfor file in files:\n  for line in file:     ## read each file line by line\n    sumx += line\n    n += 1\nmean = sumx / n\nfor file in files:\n  for line in file:\n    tss += (line - mean)**2\nvariance = tss / (n - 1)\nstandard_deviation = sqrt(variance) \n```\n\nThis is good, but can we do better?  ","user":"anonymous","dateUpdated":"2018-07-09T23:17:04-0400","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Solution Method 1</h2>\n<p>We will have to iterate over all the files and calculate the statistics piece-meal. </p>\n<p>Pseudo code follows. Your pseudo code should be readable! </p>\n<pre><code>sumx = 0\nn = 0\ntss = 0 \nsum_centered_x = 0\nfor file in files:\n  for line in file:     ## read each file line by line\n    sumx += line\n    n += 1\nmean = sumx / n\nfor file in files:\n  for line in file:\n    tss += (line - mean)**2\nvariance = tss / (n - 1)\nstandard_deviation = sqrt(variance) \n</code></pre>\n<p>This is good, but can we do better?</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1531192624097_-1642678572","id":"20180706-220405_1711217816","dateCreated":"2018-07-09T23:17:04-0400","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:42790"},{"text":"%md\n## Solution Method 2\n\nMethod 1 requires two passes at each file.  So with 100 files, we have 200 passes.  The main reason for this is because $\\mu$ is involved in the variance calculation.  We can break out our formulas and accomplish everything with one pass at the data.  \n\n\\\\( \\sigma^2 = \\sum (x^2 - 2\\mu x + \\mu^2) / (n-1) \\\\)\n\nNotice that \n\n\\\\((n-1)\\sigma^2 = \\sum (x - \\mu)^2 = \\left(\\sum x^2\\right) - n\\mu^2\\\\)\n\nThis lets us do \n\n```\nsumx = 0\nsumx2 = 0\nn = 0\nfor file in files:\n  for line in file:\n    sumx += line\n    sumx2 += line**2\n    n += 1\nmean = sumx / n\nvariance = sumx2 - n*(mean)**2\nvariance /= n-1\nstandard_deviation = sqrt(variance) \n```","user":"anonymous","dateUpdated":"2018-07-09T23:25:02-0400","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Solution Method 2</h2>\n<p>Method 1 requires two passes at each file. So with 100 files, we have 200 passes. The main reason for this is because $\\mu$ is involved in the variance calculation. We can break out our formulas and accomplish everything with one pass at the data. </p>\n<p>\\( \\sigma^2 = \\sum (x^2 - 2\\mu x + \\mu^2) / (n-1) \\)</p>\n<p>Notice that </p>\n<p>\\((n-1)\\sigma^2 = \\sum (x - \\mu)^2 = \\left(\\sum x^2\\right) - n\\mu^2\\)</p>\n<p>This lets us do </p>\n<pre><code>sumx = 0\nsumx2 = 0\nn = 0\nfor file in files:\n  for line in file:\n    sumx += line\n    sumx2 += line**2\n    n += 1\nmean = sumx / n\nvariance = sumx2 - n*(mean)**2\nvariance /= n-1\nstandard_deviation = sqrt(variance) \n</code></pre>\n</div>"}]},"apps":[],"jobName":"paragraph_1531192624097_-2042028430","id":"20180706-220414_991613494","dateCreated":"2018-07-09T23:17:04-0400","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:42791"},{"text":"%spark\nimport java.io.PrintWriter\nimport scala.util.Random.nextGaussian\nimport scala.math.{pow, sqrt}\n\nobject DescStats {\n    \n    def main(args: Array[String] = Array()) = {\n        \n        // generate data\n        for(i <- 0 until 10) { \n        val stddev = 4d  \n        val mean = 10d  \n        val pw = new PrintWriter(s\"file$i.txt\")\n        val records = (scala.util.Random.nextDouble * 200).toInt\n        for(i <- 0 until records) pw.write( (stddev*nextGaussian + mean) + \"\\n\")\n        pw.close\n        }\n\n        import java.io.File\n        val f = new File(\".\")\n        val fs = f.listFiles.filter{ _.toString.contains(\".txt\") };\n\n        def helper(f: File): (Double, Double, Double) = { \n            val src = scala.io.Source.fromFile(f)\n            val data = src.getLines\n            val map = data.map{ _.toDouble }.map{ value => (value, value*value, 1d )}\n            val reduce = map.foldLeft( (0d, 0d, 0d) ){ (x, y) => (x._1 + y._1, x._2 + y._2, x._3 + y._3)}\n            src.close\n            reduce\n        }\n\n        fs.map(helper).foreach{ \n            case (sumx, sumx2, n) => \n            println(f\"sumx: ${sumx}%7.2f, sumx2: ${sumx2}%8.2f, n: $n%4.0f\")\n        }\n\n        val (sumX, sumX2, n) = fs.map(helper).foldLeft( (0d,0d,0d) ){ (x,y) => (x._1 + y._1, x._2 + y._2, x._3 + y._3 )}\n\n        val mean = sumX / n\n        val variance = (sumX2 - n * pow(mean, 2))/(n-1)\n        println(f\"total mean => ${mean}%2.3f\\ntotal std dev => ${sqrt(variance)}%2.3f\")\n\n        fs.foreach{ _.delete }\n    }\n}\n\nDescStats.main()","user":"anonymous","dateUpdated":"2018-07-09T23:24:52-0400","config":{"tableHide":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import java.io.PrintWriter\nimport scala.util.Random.nextGaussian\nimport scala.math.{pow, sqrt}\ndefined object DescStats\nsumx:  332.57, sumx2:  4148.95, n:   32\nsumx:  323.28, sumx2:  3479.16, n:   33\nsumx:  778.20, sumx2:  8980.36, n:   78\nsumx:  633.48, sumx2:  7158.10, n:   64\nsumx:  129.15, sumx2:  1300.91, n:   14\nsumx: 1769.17, sumx2: 21166.04, n:  169\nsumx: 1143.42, sumx2: 13975.12, n:  110\nsumx: 2014.10, sumx2: 24455.48, n:  190\nsumx:  845.71, sumx2:  9360.89, n:   90\nsumx:  164.95, sumx2:  1598.94, n:   20\ntotal mean => 10.168\ntotal std dev => 4.021\n"}]},"apps":[],"jobName":"paragraph_1531192624098_-397169258","id":"20180706-212448_1457623108","dateCreated":"2018-07-09T23:17:04-0400","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:42793"},{"text":"%md\n# Problem 4 \n\nOne hot encoding\nConvert\n\n|id|\tcity|\n|--|--|\n|1|\tboston|\n|2\t|nyc|\n|3\t|tokyo|\n|4\t|boston|\n|5\t|tokyo|\n|6\t|tokyo|\n|..|\t..|\nto\n\n|id|\tohe|\n|--|--|\n|1\t|[1,0,0]|\n|2\t|[0,1,0]|\n|3\t|[0,0,1]|\n|4\t|[1,0,0]|\n|5\t|[0,0,1]|\n|6\t|[0,0,1]|\n|..|\t..|\n","user":"anonymous","dateUpdated":"2018-07-09T23:17:04-0400","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Problem 4</h1>\n<p>One hot encoding<br/>Convert</p>\n<table>\n  <thead>\n    <tr>\n      <th>id</th>\n      <th>city</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>boston</td>\n    </tr>\n    <tr>\n      <td>2 </td>\n      <td>nyc</td>\n    </tr>\n    <tr>\n      <td>3 </td>\n      <td>tokyo</td>\n    </tr>\n    <tr>\n      <td>4 </td>\n      <td>boston</td>\n    </tr>\n    <tr>\n      <td>5 </td>\n      <td>tokyo</td>\n    </tr>\n    <tr>\n      <td>6 </td>\n      <td>tokyo</td>\n    </tr>\n    <tr>\n      <td>..</td>\n      <td>..</td>\n    </tr>\n  </tbody>\n</table>\n<p>to</p>\n<table>\n  <thead>\n    <tr>\n      <th>id</th>\n      <th>ohe</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1 </td>\n      <td>[1,0,0]</td>\n    </tr>\n    <tr>\n      <td>2 </td>\n      <td>[0,1,0]</td>\n    </tr>\n    <tr>\n      <td>3 </td>\n      <td>[0,0,1]</td>\n    </tr>\n    <tr>\n      <td>4 </td>\n      <td>[1,0,0]</td>\n    </tr>\n    <tr>\n      <td>5 </td>\n      <td>[0,0,1]</td>\n    </tr>\n    <tr>\n      <td>6 </td>\n      <td>[0,0,1]</td>\n    </tr>\n    <tr>\n      <td>..</td>\n      <td>..</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}]},"apps":[],"jobName":"paragraph_1531192624098_-174278615","id":"20180706-212649_1240534564","dateCreated":"2018-07-09T23:17:04-0400","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:42794"},{"text":"%md\n## Solution \n\n\n### What you should now\n* loops\n* dictionary\n* concept of one hot encoding\n\n\n### Considerations\n1. How many unique cities are in the file - this will certainly impact the length of our one hot encoded vector\n2. Are ids unique? For example, is id 1 repeated anywhere else in the data set?\n3. Outline of the approach.\n4. We'll assume that we don't know the total number of distinct cities in the dataset. Furthermore, the ids are unique.\n\n\ncreate a Set of all cities. Ordering will not mater.\nStore the size of this set, denote this as  n\n\nour one hot encoder is a function that maps the cities in our dataset to a sequence of ones and zeros.  The one occurs in at the index of the vector that coincides with the index of the city in the set.  ","user":"anonymous","dateUpdated":"2018-07-09T23:24:47-0400","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Solution</h2>\n<h3>What you should now</h3>\n<ul>\n  <li>loops</li>\n  <li>dictionary</li>\n  <li>concept of one hot encoding</li>\n</ul>\n<h3>Considerations</h3>\n<ol>\n  <li>How many unique cities are in the file - this will certainly impact the length of our one hot encoded vector</li>\n  <li>Are ids unique? For example, is id 1 repeated anywhere else in the data set?</li>\n  <li>Outline of the approach.</li>\n  <li>We&rsquo;ll assume that we don&rsquo;t know the total number of distinct cities in the dataset. Furthermore, the ids are unique.</li>\n</ol>\n<p>create a Set of all cities. Ordering will not mater.<br/>Store the size of this set, denote this as n</p>\n<p>our one hot encoder is a function that maps the cities in our dataset to a sequence of ones and zeros. The one occurs in at the index of the vector that coincides with the index of the city in the set.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1531192624098_-47112257","id":"20180706-220820_1754811298","dateCreated":"2018-07-09T23:17:04-0400","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:42795"},{"text":"%md\n### Method 1\nAssume that it is known how many different cities are in the dataset, for our purposes, 3 (boston, tokyo and nyc).\ncreate a Set of all cities. Ordering will not mater.\nStore the size of this set, denote this as  n\n\nour one hot encoder is a function  \\\\(ohe:cities \\to \\\\{0,1\\\\}^n\\\\) with \\\\(\\\\{0,1\\\\}^n\\\\) a binary sequence of length \\\\(n\\\\), with \\\\(1\\\\) in the \\\\(i^{th}\\\\) position and \\\\(0\\\\) elsewhere.  \n","user":"anonymous","dateUpdated":"2018-07-09T23:24:44-0400","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Method 1</h3>\n<p>Assume that it is known how many different cities are in the dataset, for our purposes, 3 (boston, tokyo and nyc).<br/>create a Set of all cities. Ordering will not mater.<br/>Store the size of this set, denote this as n</p>\n<p>our one hot encoder is a function \\(ohe:cities \\to \\{0,1\\}^n\\) with \\(\\{0,1\\}^n\\) a binary sequence of length \\(n\\), with \\(1\\) in the \\(i^{th}\\) position and \\(0\\) elsewhere.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1531192624099_982587141","id":"20180706-221645_76398123","dateCreated":"2018-07-09T23:17:04-0400","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:42796"},{"text":"%spark\nobject OheMethod1 {\n    \n    def main(args: Array[String] = Array()) = {\n        val cities = Array(\n        \"boston\",\n        \"nyc\",\n        \"tokyo\",\n        \"boston\",\n        \"tokyo\",\n        \"tokyo\")\n\n        val citiesMap = Set(cities:_*).zipWithIndex.toMap\n        val numCities = citiesMap.size\n        val oheCities = cities.map{\n          city => (citiesMap(city), numCities)\n        }.map{\n          elem =>\n          val ohe = Array.fill(elem._2){0d}\n          ohe(elem._1) = 1d\n          ohe\n        }\n\n        cities.zip(oheCities).foreach {case( c, o) => println(s\"${c} \\t, ${o.mkString(\"[\",\",\",\"]\")}\") }\n    }\n}\nOheMethod1.main()","user":"anonymous","dateUpdated":"2018-07-09T23:17:04-0400","config":{"tableHide":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"defined object OheMethod1\nboston \t, [1.0,0.0,0.0]\nnyc \t, [0.0,1.0,0.0]\ntokyo \t, [0.0,0.0,1.0]\nboston \t, [1.0,0.0,0.0]\ntokyo \t, [0.0,0.0,1.0]\ntokyo \t, [0.0,0.0,1.0]\n"}]},"apps":[],"jobName":"paragraph_1531192624099_1065307972","id":"20180706-221553_353192897","dateCreated":"2018-07-09T23:17:04-0400","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:42797"},{"text":"%md\n### Method 2\nThe above solution is good, but suppose that the dataset is too big for main memory, therefore, we wouldn't be able to create the city Set as we did previously. We can handle this by making a few small changes to the code\n1. start with a mutable map with string key and integer value.\n2. initialize a counter (we use an java AtomicInteger to take advantage of reference)\n3. iterate over the data. If a city is not in your map, increment the counter and add the city as key and the counter as value.\n4. iterate once more to create the one hot encoded vector","user":"anonymous","dateUpdated":"2018-07-09T23:24:41-0400","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Method 2</h3>\n<p>The above solution is good, but suppose that the dataset is too big for main memory, therefore, we wouldn&rsquo;t be able to create the city Set as we did previously. We can handle this by making a few small changes to the code<br/>1. start with a mutable map with string key and integer value.<br/>2. initialize a counter (we use an java AtomicInteger to take advantage of reference)<br/>3. iterate over the data. If a city is not in your map, increment the counter and add the city as key and the counter as value.<br/>4. iterate once more to create the one hot encoded vector</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1531192624099_-1679729168","id":"20180706-221658_198185251","dateCreated":"2018-07-09T23:17:04-0400","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:42798"},{"text":"%spark\nimport java.util.concurrent.atomic.AtomicInteger\nimport scala.collection.mutable.{Map => MutMap}\n\nobject OheMethod2 { \n\n    def main(args: Array[String] = Array()) = { \n        val cities = Array(\n          \"boston\",\n          \"nyc\",\n          \"tokyo\",\n          \"boston\",\n          \"tokyo\",\n          \"tokyo\")\n        val numClasses = new AtomicInteger\n        val citiesMutMap = MutMap[String, Int]()\n        val oheCities = cities.map{ city =>\n          if(citiesMutMap contains city) {\n            (numClasses, citiesMutMap(city))\n          } else {\n            citiesMutMap.update(city, numClasses.getAndAdd(1) )\n            (numClasses, citiesMutMap(city))\n          }\n        }.map{\n          tup =>\n            val ohe = Array.fill(tup._1.get){0d}\n            ohe(tup._2) = 1d\n            ohe\n        }\n\n        (cities zip oheCities).foreach{ case(c,i) => println(s\"${c} \\t, ${i.mkString(\"[\",\",\",\"]\")}\")}\n    }\n}\n\nOheMethod2.main()","user":"anonymous","dateUpdated":"2018-07-09T23:24:39-0400","config":{"tableHide":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import java.util.concurrent.atomic.AtomicInteger\nimport scala.collection.mutable.{Map=>MutMap}\ndefined object OheMethod2\nboston \t, [1.0,0.0,0.0]\nnyc \t, [0.0,1.0,0.0]\ntokyo \t, [0.0,0.0,1.0]\nboston \t, [1.0,0.0,0.0]\ntokyo \t, [0.0,0.0,1.0]\ntokyo \t, [0.0,0.0,1.0]\n"}]},"apps":[],"jobName":"paragraph_1531192624099_-1425075097","id":"20180706-221606_83229326","dateCreated":"2018-07-09T23:17:04-0400","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:42799"},{"text":"%spark\n// nice feature of zeppelin notebooks\nval cities = Array(\n    \"boston\",\n    \"nyc\",\n    \"tokyo\",\n    \"boston\",\n    \"tokyo\",\n    \"tokyo\")\nsc.parallelize(cities).toDF(\"city\").createOrReplaceTempView(\"cities\")","user":"anonymous","dateUpdated":"2018-07-09T23:24:33-0400","config":{"colWidth":6,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","tableHide":true,"editorHide":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1531192755278_-368567063","id":"20180709-231915_784330899","dateCreated":"2018-07-09T23:19:15-0400","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:46288","dateFinished":"2018-07-09T23:20:23-0400","dateStarted":"2018-07-09T23:20:22-0400","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"cities: Array[String] = Array(boston, nyc, tokyo, boston, tokyo, tokyo)\n"}]}},{"text":"%sql\nselect city, sum(1) as n\nfrom cities\ngroup by 1","user":"anonymous","dateUpdated":"2018-07-09T23:24:36-0400","config":{"colWidth":6,"fontSize":9,"enabled":true,"results":{"0":{"graph":{"mode":"pieChart","height":254.149,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"city":"string","n":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{}},"helium":{}}},"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql","tableHide":true,"editorHide":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1531192825967_-783501247","id":"20180709-232025_1756608508","dateCreated":"2018-07-09T23:20:25-0400","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:46385","dateFinished":"2018-07-09T23:20:41-0400","dateStarted":"2018-07-09T23:20:39-0400","results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"city\tn\ntokyo\t3\nnyc\t1\nboston\t2\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://192.168.1.188:4040/jobs/job?id=16","http://192.168.1.188:4040/jobs/job?id=17","http://192.168.1.188:4040/jobs/job?id=18","http://192.168.1.188:4040/jobs/job?id=19","http://192.168.1.188:4040/jobs/job?id=20"],"interpreterSettingId":"spark"}}},{"text":"%md\n# Problem 4 \nOne hot encoding\nharder version\nData - You are interested in predicting whether a user will see a movie based on the movies they have seen in the theatre in the last year. The dataset has two columns, one for the user id and one for the movie they saw (a movie name). The data is as follows\n\nUser\t|movie\n--|--\n1|\tJumani\n1|\tA Quiet Place\n1|\tGame Night\n2|\tJurasic World\n2|\tThe Last Jedi\n2|\tHereditary\n2|\tCoco\n3|\tMother\n..|..\nAnd we need to convert it to something like\n\nuser|\tm1|\tm2|\tm3|\tm4|\tm5|\tm6|\tm7|\tm8|\t..|\tmn|\n--  |--   |-- |-- |-- |-- |-- |-- |-- |-- |--|\n1|\t1|\t1|\t0|\t0|\t1|\t0|\t0|\t0|\t..|\t0|\n2|\t0|\t0|\t1|\t1|\t0|\t0|\t1|\t1|\t..|\t0|\n3|\t0|\t0|\t0|\t0|\t0|\t0|\t0|\t0|\t..|\t0|\n..|..| ..| ..| ..| ..| ..| ..| ..| ..|.. |","user":"anonymous","dateUpdated":"2018-07-09T23:17:04-0400","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Problem 4</h1>\n<p>One hot encoding<br/>harder version<br/>Data - You are interested in predicting whether a user will see a movie based on the movies they have seen in the theatre in the last year. The dataset has two columns, one for the user id and one for the movie they saw (a movie name). The data is as follows</p>\n<table>\n  <thead>\n    <tr>\n      <th>User </th>\n      <th>movie</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>Jumani</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>A Quiet Place</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>Game Night</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>Jurasic World</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>The Last Jedi</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>Hereditary</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>Coco</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>Mother</td>\n    </tr>\n    <tr>\n      <td>..</td>\n      <td>..</td>\n    </tr>\n  </tbody>\n</table>\n<p>And we need to convert it to something like</p>\n<table>\n  <thead>\n    <tr>\n      <th>user</th>\n      <th>m1</th>\n      <th>m2</th>\n      <th>m3</th>\n      <th>m4</th>\n      <th>m5</th>\n      <th>m6</th>\n      <th>m7</th>\n      <th>m8</th>\n      <th>..</th>\n      <th>mn</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>..</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>..</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>..</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>..</td>\n      <td>..</td>\n      <td>..</td>\n      <td>..</td>\n      <td>..</td>\n      <td>..</td>\n      <td>..</td>\n      <td>..</td>\n      <td>..</td>\n      <td>..</td>\n      <td>.. </td>\n    </tr>\n  </tbody>\n</table>\n</div>"}]},"apps":[],"jobName":"paragraph_1531192624100_-1279063692","id":"20180706-222013_231756612","dateCreated":"2018-07-09T23:17:04-0400","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:42800"},{"text":"%md\n## Solution \n\n### Considerations\n1. How many unique movies are in the file\n2.  Can a user movie combination appear more than once (I know a guy that saw fire fly in the theather 4 times)\n3. Is the data sorted in any fashion\n\n### What you should now\n1. Reading files\n2. loops\n3. dictionary\n4. storing sparse data\n5. writing classes\n\nApproach \n\n* Do not assume the data is sorted.\n* Assume the user movie combination is unique\n\nWe'll initialize a variable c to keep track of the number of unique movies in the data set, then convert our dataset to key value pairs where each key is a user id and each value is an array containing the movie id which the user has seen. These arrays will then be convert to a sparse vector, for us this will just be a tuple of type  (Int, Vector[Int], Vector[Double]). The first element in the tuple is the length of the vector, the second element will be the indices which are non-zero, while the third element will contain the corresponding non-zero values.","user":"anonymous","dateUpdated":"2018-07-09T23:24:27-0400","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Solution</h2>\n<h3>Considerations</h3>\n<ol>\n  <li>How many unique movies are in the file</li>\n  <li>Can a user movie combination appear more than once (I know a guy that saw fire fly in the theather 4 times)</li>\n  <li>Is the data sorted in any fashion</li>\n</ol>\n<h3>What you should now</h3>\n<ol>\n  <li>Reading files</li>\n  <li>loops</li>\n  <li>dictionary</li>\n  <li>storing sparse data</li>\n  <li>writing classes</li>\n</ol>\n<p>Approach </p>\n<ul>\n  <li>Do not assume the data is sorted.</li>\n  <li>Assume the user movie combination is unique</li>\n</ul>\n<p>We&rsquo;ll initialize a variable c to keep track of the number of unique movies in the data set, then convert our dataset to key value pairs where each key is a user id and each value is an array containing the movie id which the user has seen. These arrays will then be convert to a sparse vector, for us this will just be a tuple of type (Int, Vector[Int], Vector[Double]). The first element in the tuple is the length of the vector, the second element will be the indices which are non-zero, while the third element will contain the corresponding non-zero values.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1531192624100_-1281353271","id":"20180706-222458_401407927","dateCreated":"2018-07-09T23:17:04-0400","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:42801"},{"text":"%spark\n\n// imports \nimport scala.collection.mutable.{Map=>MutMap}\nimport java.util.concurrent.atomic.AtomicInteger\n\n// SparseVector class\ncase class SparseVector(length: Int, indices: Vector[Int], values: Vector[Double])\n// import data\n\nobject OheHarder {\n    def main(args: Array[String] = Array()) = {\n        val path = sys.env(\"HOME\") + \"/Desktop/pgh data science/movies.csv\"\n        val src = scala.io.Source.fromFile(path)\n        val data = src.getLines.map{ _.split(\",\")}.toList.tail\n\n        val users = MutMap[String, Vector[Int]]()  // create a dictionary of users\n        val movies = MutMap[String, Int]()         // create a dictionary of movies\n        val c = new AtomicInteger                  \n\n        data.foreach{ line => \n          val Array(user, movie) = line\n          if(!movies.contains(movie)) { \n              movies.update(movie, c.getAndAdd(1))  \n          }\n          val movieId = movies(movie)\n          if(users.contains(user)) {\n              users.update(user, movieId +: users(user))\n          } else { \n              users.update(user, Vector(movieId))\n          }\n        }\n        for(user <- users.keys) { \n           users.update( user, users(user).sortWith(_ < _))\n        }\n        val ohe = users.map{ case(user, movies) => (user, SparseVector(c.get, movies, Vector.fill(movies.length){1d}))}\n        ohe.foreach(println)\n    }\n}\n\nOheHarder.main()","user":"anonymous","dateUpdated":"2018-07-09T23:24:23-0400","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true,"tableHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import scala.collection.mutable.{Map=>MutMap}\nimport java.util.concurrent.atomic.AtomicInteger\ndefined class SparseVector\ndefined object OheHarder\n(2,SparseVector(8,Vector(3, 4, 5, 6),Vector(1.0, 1.0, 1.0, 1.0)))\n(1,SparseVector(8,Vector(0, 1, 2),Vector(1.0, 1.0, 1.0)))\n(3,SparseVector(8,Vector(7),Vector(1.0)))\n"}]},"apps":[],"jobName":"paragraph_1531192624100_-1561597386","id":"20180706-222720_1899044086","dateCreated":"2018-07-09T23:17:04-0400","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:42802"},{"text":"%md\n\n## Problem 5\n\n\\\\(Z\\\\) is a random \\\\(Bernoulli(1-p)\\\\) variable\n\n\\\\(Y\\\\) is a random discrete \\\\(Uniform[0, N-1]\\\\) variable  if \\\\(Z = 1\\\\), otherwise \\\\(Y\\\\) is 0\n\nCalculate \n1.  The PDF for \\\\(Y\\\\)\n2.  The expected value of \\\\(Z\\\\) given \\\\(Y\\\\) is zero.\n","user":"anonymous","dateUpdated":"2018-07-09T23:24:04-0400","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Problem 5</h2>\n<p>\\(Z\\) is a random \\(Bernoulli(1-p)\\) variable</p>\n<p>\\(Y\\) is a random discrete \\(Uniform[0, N-1]\\) variable if \\(Z = 1\\), otherwise \\(Y\\) is 0</p>\n<p>Calculate<br/>1. The PDF for \\(Y\\)<br/>2. The expected value of \\(Z\\) given \\(Y\\) is zero.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1531192624101_-1099341124","id":"20180706-223326_19885352","dateCreated":"2018-07-09T23:17:04-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:42803","dateFinished":"2018-07-09T23:24:04-0400","dateStarted":"2018-07-09T23:24:04-0400"},{"text":"%md\n\n### Solution\n\nTo complete this you should know the following \n1.  PDF (probability density function)\n2.  Calculating expected values\n3.  Conditional probabilities\n\nThe first part is fairly straight forward.  \n\n\\\\(Y \\sim Uniform[0,N-1]\\\\) with probability \\\\(1-p\\\\) and \\\\(0\\\\) with probability \\\\(p\\\\).  Then  \\\\(p(Y=y)\\\\)  is  \\\\((1−p)/N\\\\) if  \\\\(Y>0\\\\) and  \\\\(p+(1−p)/N\\\\) if  \\\\(Y=0\\\\)\n \nLastly, \\\\( \\mathbb{E}[Z | Y = 0]\\\\ = \\sum_{z} z\\cdot p(Z = z | Y = 0) = p(Z = 1 | Y = 0) = P(Z = 1 \\cap Y = 0) / P( Y = 0) = \\frac{p}{p + (1-p)/N}\\\\)","user":"anonymous","dateUpdated":"2018-07-09T23:24:19-0400","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1531192661458_-664380851","id":"20180709-231741_1867718913","dateCreated":"2018-07-09T23:17:41-0400","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:46186","dateFinished":"2018-07-09T23:24:16-0400","dateStarted":"2018-07-09T23:24:16-0400","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Solution</h3>\n<p>To complete this you should know the following<br/>1. PDF (probability density function)<br/>2. Calculating expected values<br/>3. Conditional probabilities</p>\n<p>The first part is fairly straight forward. </p>\n<p>\\(Y \\sim Uniform[0,N-1]\\) with probability \\(1-p\\) and \\(0\\) with probability \\(p\\). Then \\(p(Y=y)\\) is \\((1−p)/N\\) if \\(Y&gt;0\\) and \\(p+(1−p)/N\\) if \\(Y=0\\)</p>\n<p>Lastly, \\( \\mathbb{E}[Z | Y = 0]\\ = \\sum_{z} z\\cdot p(Z = z | Y = 0) = p(Z = 1 | Y = 0) = P(Z = 1 \\cap Y = 0) / P( Y = 0) = \\frac{p}{p + (1-p)/N}\\)</p>\n</div>"}]}},{"text":"%md\n# Problem 6 \n\nYou work for an e-commerce site and you have 1MM customers. Marketing is toying with the idea of introducing a reward card. They design the following test to decide whether a reward card is worth it.\n\nThey randomly sample 10% of the customer base to conduct the experiment and the remaining 90% is used as a control group. This 10% will be offered the reward card.\nOf the 10%, only 5% sign up. Of those who signed up, you see them spending $130 per visit, while those who don't spend $98 per visit.\n\nThe control group has average spend of $99 per trip\n\nIf the rewards cost $10 per customer that signs up and there is are fixed costs of $5K, would you recommend rolling out the reward card?\n","user":"anonymous","dateUpdated":"2018-07-09T23:17:04-0400","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Problem 6</h1>\n<p>You work for an e-commerce site and you have 1MM customers. Marketing is toying with the idea of introducing a reward card. They design the following test to decide whether a reward card is worth it.</p>\n<p>They randomly sample 10% of the customer base to conduct the experiment and the remaining 90% is used as a control group. This 10% will be offered the reward card.<br/>Of the 10%, only 5% sign up. Of those who signed up, you see them spending $130 per visit, while those who don&rsquo;t spend $98 per visit.</p>\n<p>The control group has average spend of $99 per trip</p>\n<p>If the rewards cost $10 per customer that signs up and there is are fixed costs of $5K, would you recommend rolling out the reward card?</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1531192624101_927313429","id":"20180707-163954_2014866206","dateCreated":"2018-07-09T23:17:04-0400","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:42804"},{"text":"%md\n### Solution \n\nBased on the construction of test and control groups, we would expect that 5% of customers in the control group would probably have signed up for the card if they were offered - so any difference in their average spend vs the test group will be attributed to the rewards card.\n\nWe can assume that 95 percent of the Control group is identical to the 95% of the test group who didn't sign up for the card, so we'll assume they have a similar spend of $98 per vist.\n\nThus the average spend of the control group is \\\\(99=0.95\\cdot 98+0.05 \\cdot x\\\\), where  \\\\(x\\\\) is the 5% of the control that we figure would sign up for the card having been offered. Thus,  \\\\(x=$118\\\\).  This means that the rewards card generated $12 of additional spend per customer that signed up.\n\nNow we must account for the cost. We had 5,000 people sign up, which resulted in an incremental spend of $12 per person.\nThe costs the company incurs is $5,000 fix cost and $10 variable cost, we end up at making $5,000 at the end of the expermiment \\\\((12−10)⋅5000−5000=5000\\\\). We should consider rolling out the reward program!!!\n","user":"anonymous","dateUpdated":"2018-07-09T23:23:30-0400","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Solution</h3>\n<p>Based on the construction of test and control groups, we would expect that 5% of customers in the control group would probably have signed up for the card if they were offered - so any difference in their average spend vs the test group will be attributed to the rewards card.</p>\n<p>We can assume that 95 percent of the Control group is identical to the 95% of the test group who didn&rsquo;t sign up for the card, so we&rsquo;ll assume they have a similar spend of $98 per vist.</p>\n<p>Thus the average spend of the control group is \\(99=0.95\\cdot 98+0.05 \\cdot x\\), where \\(x\\) is the 5% of the control that we figure would sign up for the card having been offered. Thus, \\(x=$118\\). This means that the rewards card generated $12 of additional spend per customer that signed up.</p>\n<p>Now we must account for the cost. We had 5,000 people sign up, which resulted in an incremental spend of $12 per person.<br/>The costs the company incurs is $5,000 fix cost and $10 variable cost, we end up at making $5,000 at the end of the expermiment \\((12−10)⋅5000−5000=5000\\). We should consider rolling out the reward program!!!</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1531192624101_1360849582","id":"20180707-164031_423052729","dateCreated":"2018-07-09T23:17:04-0400","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:42805"},{"text":"%md\n\n# Problem 8\n\nYou have two matrices, call them \\\\(X\\\\) and \\\\(Y\\\\).  Matrix \\\\(X\\\\) has \\\\(m\\\\) rows and \\\\(n\\\\) columns, while \\\\(Y\\\\) has \\\\(m\\\\) columns and \\\\(l\\\\) rows.  Both matrices are stored in a SQL database.  For our purpose suppose that the matrices are stored in table `x` and table `y`.  The tables have 3 columns each:\n\n1. Row - index of the row for the corresponding value\n2. Column - index of the column for the corresponding value\n3. Value - the value\n\nCompute \\\\(XY\\\\) by writing a SQL query\n","user":"anonymous","dateUpdated":"2018-07-09T23:17:04-0400","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Problem 8</h1>\n<p>You have two matrices, call them \\(X\\) and \\(Y\\). Matrix \\(X\\) has \\(m\\) rows and \\(n\\) columns, while \\(Y\\) has \\(m\\) columns and \\(l\\) rows. Both matrices are stored in a SQL database. For our purpose suppose that the matrices are stored in table <code>x</code> and table <code>y</code>. The tables have 3 columns each:</p>\n<ol>\n  <li>Row - index of the row for the corresponding value</li>\n  <li>Column - index of the column for the corresponding value</li>\n  <li>Value - the value</li>\n</ol>\n<p>Compute \\(XY\\) by writing a SQL query</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1531192624102_2572612","id":"20180706-212722_1427252847","dateCreated":"2018-07-09T23:17:04-0400","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:42806"},{"text":"%md\n### Solution \n\nMatrix mutliplication between \\\\(X\\\\) and \\\\(Y\\\\) are defined is defined as \n\n\\\\(Z_{i,j} = \\sum_{k} X_{i,k}Y_{k,j}\\\\)\n\nThe query should be written to join `x` and `y` on `x`'s column index and `y`'s row index.  ","user":"anonymous","dateUpdated":"2018-07-09T23:23:24-0400","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Solution</h3>\n<p>Matrix mutliplication between \\(X\\) and \\(Y\\) are defined is defined as </p>\n<p>\\(Z_{i,j} = \\sum_{k} X_{i,k}Y_{k,j}\\)</p>\n<p>The query should be written to join <code>x</code> and <code>y</code> on <code>x</code>&rsquo;s column index and <code>y</code>&rsquo;s row index.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1531192624102_-1316509874","id":"20180707-164347_442405688","dateCreated":"2018-07-09T23:17:04-0400","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:42807"},{"text":"%spark\n// generate data \ncase class MatrixElement(row: Int, column: Int, value: Double)\nimport scala.util.Random.nextGaussian\nval m = 3\nval n = 2\nval l = 1\nval x = sc.parallelize (for{ i <- 0 to m; \n     j <- 0 to n} yield MatrixElement(i,j,nextGaussian)).toDF\nval y = sc.parallelize (for{ i <- 0 to n; \n     j <- 0 to l} yield MatrixElement(i,j,nextGaussian)).toDF\nx.createOrReplaceTempView(\"x\")\ny.createOrReplaceTempView(\"y\")\n          ","user":"anonymous","dateUpdated":"2018-07-09T23:23:21-0400","config":{"tableHide":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"defined class MatrixElement\nimport scala.util.Random.nextGaussian\nm: Int = 3\nn: Int = 2\nl: Int = 1\nx: org.apache.spark.sql.DataFrame = [row: int, column: int ... 1 more field]\ny: org.apache.spark.sql.DataFrame = [row: int, column: int ... 1 more field]\n"}]},"apps":[],"jobName":"paragraph_1531192624102_-1391272997","id":"20180707-164559_1402222922","dateCreated":"2018-07-09T23:17:04-0400","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:42808"},{"text":"-- %sql\n-- select x.row as xrow, x.column as xcolumn, x.value as xvalue, y.row as yrow, y.column as ycolumn, y.value as yvalue\n-- from x inner join y\n-- on x.column = y.row \n-- where x.row = 0 and y.column = 0","user":"anonymous","dateUpdated":"2018-07-09T23:17:04-0400","config":{"tableHide":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"xrow":"string","xcolumn":"string","xvalue":"string","yrow":"string","ycolumn":"string","yvalue":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{}}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:66: error: not found: value --\n       -- %sql\n       ^\n<console>:66: error: missing argument list for method sql in class SparkSession\nUnapplied methods are only converted to functions when a function type is expected.\nYou can make this conversion explicit by writing `sql _` or `sql(_)` instead of `sql`.\n       -- %sql\n           ^\n"}]},"apps":[],"jobName":"paragraph_1531192624102_1980066808","id":"20180707-165727_1731931092","dateCreated":"2018-07-09T23:17:04-0400","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:42809"},{"text":"%sql\nselect x.row, y.column, sum(x.value * y.value) as value\nfrom x inner join y\non x.column = y.row \ngroup by x.row, y.column\norder by 1, 2\n","user":"anonymous","dateUpdated":"2018-07-09T23:23:26-0400","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"row":"string","column":"string","value":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{}}}},"enabled":true,"tableHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"row\tcolumn\tvalue\n0\t0\t-0.9200268293060925\n0\t1\t-8.97421207628667\n0\t2\t-1.5706762288839224\n0\t3\t1.5144616580634018\n1\t0\t-11.881940175912982\n1\t1\t-0.35198420322070095\n1\t2\t8.200311016178091\n1\t3\t-0.5654672024539847\n2\t0\t-0.7237833471400175\n2\t1\t-0.989052094249181\n2\t2\t-8.379145926836543\n2\t3\t2.642650392114391\n3\t0\t-7.0553829958171\n3\t1\t4.0643082713438545\n3\t2\t6.774367595645654\n3\t3\t-3.8349326445416314\n4\t0\t2.689827911448217\n4\t1\t-6.649606402022119\n4\t2\t3.2980959428955883\n4\t3\t8.375207181770227\n5\t0\t9.163405031304068\n5\t1\t5.69054151564136\n5\t2\t-1.004862780491469\n5\t3\t-3.768317539316235\n6\t0\t-6.389250563696436\n6\t1\t5.006031716145783\n6\t2\t-3.291505318964304\n6\t3\t-10.954546632226812\n7\t0\t1.1438989138224187\n7\t1\t-1.0873965209747984\n7\t2\t5.512034227204335\n7\t3\t0.10855337288334227\n8\t0\t-0.39572495468098756\n8\t1\t-1.1132101069199507\n8\t2\t3.1499638607754816\n8\t3\t7.959256495815833\n9\t0\t-0.5621306703348907\n9\t1\t1.4601498800315018\n9\t2\t-6.673791270426753\n9\t3\t-7.01501502592723\n10\t0\t-1.6673157726058943\n10\t1\t9.871968187115488\n10\t2\t3.147881250842506\n10\t3\t-2.5729482026365886\n11\t0\t4.228924360487767\n11\t1\t3.30559509188151\n11\t2\t-0.652927705889868\n11\t3\t-1.2367558631537543\n12\t0\t-6.485652795170808\n12\t1\t-4.139148177398012\n12\t2\t-7.681551062171124\n12\t3\t-1.9393117248681806\n13\t0\t2.779289391413349\n13\t1\t7.835755395689294\n13\t2\t0.007399025168384088\n13\t3\t-4.561848394370029\n14\t0\t0.42284658671412345\n14\t1\t9.857959150491622\n14\t2\t-4.878639019384517\n14\t3\t-12.075269621381581\n15\t0\t-9.768603720049127\n15\t1\t-0.14257299616003227\n15\t2\t-1.7157258472992694\n15\t3\t-4.269553540172648\n16\t0\t-0.5365215714755092\n16\t1\t3.3894867395674475\n16\t2\t-4.11054330470775\n16\t3\t-6.5558301986238146\n17\t0\t-2.1596116148813045\n17\t1\t8.517004535308844\n17\t2\t-0.30173493988919986\n17\t3\t-9.745026852879363\n18\t0\t-3.971022619848346\n18\t1\t0.6741394053031904\n18\t2\t-2.9848301905283168\n18\t3\t-5.656647569987836\n19\t0\t10.65943856429536\n19\t1\t-3.1516830038118275\n19\t2\t-5.077500000243036\n19\t3\t3.4035768155795507\n20\t0\t-8.773228058898837\n20\t1\t-0.2215751199343473\n20\t2\t-4.53403270061647\n20\t3\t-4.583676209937032\n21\t0\t-4.457621795183886\n21\t1\t-5.279469116751406\n21\t2\t-6.593481143128652\n21\t3\t3.6399063404807697\n22\t0\t4.5998614551784245\n22\t1\t2.1655947636356565\n22\t2\t-0.7821746684907375\n22\t3\t-1.2668520767618106\n23\t0\t2.1703160701165722\n23\t1\t-4.547842798376907\n23\t2\t-4.243206603014738\n23\t3\t5.481243893456014\n24\t0\t4.557988038241382\n24\t1\t11.415138667606103\n24\t2\t-0.4060553219003555\n24\t3\t-8.957999885612201\n25\t0\t12.339486967157379\n25\t1\t-3.1501124841226935\n25\t2\t-8.674705237320191\n25\t3\t-0.914752954181772\n"}]},"apps":[],"jobName":"paragraph_1531192624103_-1253371659","id":"20180707-164827_942305618","dateCreated":"2018-07-09T23:17:04-0400","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:42810"},{"text":"%md\nQuestions","user":"anonymous","dateUpdated":"2018-07-09T23:17:04-0400","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Questions</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1531192624103_-1640453501","id":"20180707-165417_1641548267","dateCreated":"2018-07-09T23:17:04-0400","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:42811"},{"text":"%md\n![wham!](http://cyberschroeder.com/wp-content/uploads/2013/11/0167.jpg)\n","user":"anonymous","dateUpdated":"2018-07-09T23:17:04-0400","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"http://cyberschroeder.com/wp-content/uploads/2013/11/0167.jpg\" alt=\"wham!\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1531192624103_1611458640","id":"20180707-195419_9056878","dateCreated":"2018-07-09T23:17:04-0400","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:42812"},{"text":"%md\n","user":"anonymous","dateUpdated":"2018-07-09T23:17:04-0400","config":{"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1531192624104_5398887","id":"20180707-195528_244772041","dateCreated":"2018-07-09T23:17:04-0400","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:42813"}],"name":"PGH Data Science Interview Questions","id":"2DKEZ35D8","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"python:shared_process":[],"sh:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}